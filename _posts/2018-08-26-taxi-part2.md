---
title: "Google BigQuery Taxi Fare Predictions - Part 2"
date: 2018-08-26
tags: [regression, random forest, xgboost]
header:
  image: "/images/taxi_pic.jpg"
excerpt: "Regression, Random Forest, XGBoost"
mathjax: "true"
---

# Model preparation

On this stage we are working on regression problem to build a predictive model for taxi fares.<br>
To derive percise predictions we will take different algorithms into consideration:

1. Multiple regresssion with regularization component(L1/L2);
2. Random forest model;
3. XGBoost model.

### 1.1 Linear model without regularization

We start with spliting data on train-validation and test. Using 10% of data as test sample we train basic linear model and estimate performance metrics - MAE (mean absolute error) and RMSE (root squared error) on test. 
To simplify our code on further steps we will write a function to estimate metrics for different models. 
<details><summary>Python code</summary> 
  
 ```python
"""
- perform train_test_split() mudule for data split
- separate the  relevant features list and target as an output 

"""
train_valid_data, test_data = train_test_split(data, test_size=0.1)

features=['dropoff_longitude','dropoff_latitude', 'pickup_longitude', 'pickup_latitude', 
         'distance_trip', 'diff', 'passenger_count', 'dropoff_month', 'dropoff_day', 'dropoff_hour',
         'pickup_month', 'pickup_day', 'pickup_hour']
output='fare_amount'

"""
- define the function to compute errors 
- print the result on test data

"""

def compute_error(predictions, true_values):
    resid=true_values-predictions
    rss = sum(resid*resid)
    # computing root mean absolute error 
    mae_true=sum(abs(resid))/len(predictions)
    # computing root mean squared error 
    mse_true=rss/len(resid)
    rmse_true=np.sqrt(mse_true)
    
    print "RMSE on test equals "+ "{:.{}f}".format( rmse_true, 2 )
    print "MAE on test  equals "+"{:.{}f}".format( mae_true, 2 )  

 ```
 
</details>


Now we are ready to train base regression model on *train_valid_data* and evaluate performace on test. 

<details><summary>Python code</summary> 
  
<p>
  
 ```python
"""
- create a linear regression object
- fit with train-validation data
- make predictions on test

"""
linear=LinearRegression(normalize=True)
linear.fit(train_valid_data[features], train_valid_data[output])
predictions=linear.predict(test_data[features])
compute_error(predictions, test_data[output])

 ```
 
 </p>
</details>

 ```python
RMSE on test equals 3.09
MAE on test  equals 2.31
 ```

The results above represent performance for unregularized model. Let's check the possible improvement with *regularization parameter added.*

### 1.2 Ridge regression

Next we will use train-validation data to build regression model with L2 regularization, performing k-folds cross validation to tune regularization parameter. 
For each fold we train a model and compute mean squared and root mean squared errors to find mean across folds. Besides we are going to visualize the mean absolute error change with respect of penalty parameter value.

Display split per folds:

<details><summary>Python code</summary> 
  
<p>
  
 ```python
"""
- use number of folds k=10  
- display folds boundaries for train-validation data

"""

n = len(train_valid_data) # will use entire frame
k=10
# print boundaries for each fold 
for fold in range(k):
    start = (n*fold)/k 
    end = (n*(fold+1))/k-1
    print fold, (start, end)

 ```
 
 </p>
</details>

 ```python
0 (0, 153424)
1 (153425, 306850)
2 (306851, 460276)
3 (460277, 613701)
4 (613702, 767127)
5 (767128, 920553)
6 (920554, 1073978)
7 (1073979, 1227404)
8 (1227405, 1380830)
9 (1380831, 1534256)
 ```

Train Ridge regression for each parameter from list and compute metrics means. 

<details><summary>Python code</summary> 
  
<p>
  
 ```python
"""
- initialize the list of penalty values and starting points: split on train/validation, 
compute error for each fold, sum it up and estimate the average error for particular penalty 

"""

l2_penalty=[1e-17, 1e-12, 1e-06, 0.001, 0.01, 1, 2]
mae_sum = 0
rmse_sum = 0
mae_penalty=[]
# iterate through penalty values, create Ridge object 
for alpha in l2_penalty:
    ridge=linear_model.Ridge(alpha=alpha, normalize=True)
    for i in xrange(k):
        start=(n*i)/k
        end=(n*(i+1))/k-1
        valid=train_valid_data[start:end+1]
        training=train_valid_data[0:start].append(train_valid_data[end+1:n])
        # fitting model, making predictions 
        ridge.fit(training[features], training[output])
        predictions=ridge.predict(valid[features])
        resid=valid[output]-predictions
        # computing rss
        fold_rss = sum(resid*resid)
        # computing mean absolute error 
        fold_mae=sum(abs(resid))/len(predictions)
        mae_sum+=fold_mae
        # computing root mean squared error 
        fold_mse=fold_rss/len(resid)
        fold_rmse=np.sqrt(fold_mse)
        rmse_sum+=fold_rmse
    # estimate validation errors for each alpha 
    val_mae = mae_sum/k
    val_rmse = rmse_sum/k 
    mae_penalty.append(val_mae)
    print "RMSE for alpha=" +str(alpha)+' equals '+ "{:.{}f}".format( val_rmse, 2 )
    print "MAE for alpha="+str(alpha)+' equals '+"{:.{}f}".format( val_mae, 2 )
 ```
 
 </p>
</details>

 ```python

RMSE for alpha=1e-17 equals 3.08
MAE for alpha=1e-17 equals 2.31
RMSE for alpha=1e-12 equals 6.16
MAE for alpha=1e-12 equals 4.62
RMSE for alpha=1e-06 equals 9.25
MAE for alpha=1e-06 equals 6.93
RMSE for alpha=0.001 equals 12.33
MAE for alpha=0.001 equals 9.25
RMSE for alpha=0.01 equals 15.41
MAE for alpha=0.01 equals 11.56
RMSE for alpha=1 equals 19.38
MAE for alpha=1 equals 14.71
RMSE for alpha=2 equals 23.97
MAE for alpha=2 equals 18.40
 ```





